import pandas as pd
from sklearn import metrics
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, f1_score, precision_score
from sklearn.neural_network import MLPClassifier
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.utils import shuffle

if __name__ == '__main__':
    print("evaluating the dataset by classifying cls(whether a data sample is real data or synthetic data) class ")
    # Read real data and synthetic data
    real_data = pd.read_csv('Power_grid_real_data.csv').reset_index(drop=True)
    synthetic_data = pd.read_csv("Power_grid_synthetic_data_post.csv").sample(len(real_data))
    # Extra column generated by pandas
    del synthetic_data['Unnamed: 0']
    real_data = real_data.drop(['marker'], axis=1)
    synthetic_data = synthetic_data.drop(['marker'], axis=1)
    # ##################################
    # For base line, 50% of real dataset is marked as real,
    # 50% is marked as synthetic, then ask the ML model to classify
    # synthetic_data = real_data.sample(int(len(real_data) * 0.5))
    # real_data = real_data[~real_data.index.isin(synthetic_data.index)]
    ##################################
    # Mark the dataset
    real_data['cls'] = 0
    synthetic_data['cls'] = 1
    # ##################################################
    # combine real and synthetic dataset, shuffle them, use 70% for training, 30% for testing
    whole_data = pd.concat([real_data, synthetic_data])
    whole_data = shuffle(whole_data)
    train_data = whole_data.sample(int(len(whole_data) * 0.7))
    test_data = whole_data[~whole_data.index.isin(train_data.index)]

    # LogisticRegression#################################################################
    clf = LogisticRegression().fit(train_data.drop('cls', axis=1), train_data['cls'])
    y_pred = clf.predict(test_data.drop('cls', axis=1))
    print("LogisticRegression acc", accuracy_score(test_data['cls'], y_pred))
    print("LogisticRegression rec", recall_score(test_data['cls'], y_pred, average=None))
    print("LogisticRegression pre", precision_score(test_data['cls'], y_pred, average=None))
    print("LogisticRegression f1", f1_score(test_data['cls'], y_pred, average=None))
    print("LogisticRegression roc", roc_auc_score(test_data['cls'], y_pred, average=None))

    # SGDClassifier#################################################################
    clf = SGDClassifier()
    clf.fit(train_data.drop('cls', axis=1), train_data['cls'])
    y_pred = clf.predict(test_data.drop('cls', axis=1))
    print("SGDClassifier acc", accuracy_score(test_data['cls'], y_pred))
    print("SGDClassifier rec", recall_score(test_data['cls'], y_pred, average=None))
    print("SGDClassifier pre", precision_score(test_data['cls'], y_pred, average=None))
    print("SGDClassifier f1", f1_score(test_data['cls'], y_pred, average=None))
    print("SGDClassifier roc", roc_auc_score(test_data['cls'], y_pred, average=None))

    # Neural Network#################################################################
    clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(128, 64), random_state=1)
    clf.fit(train_data.drop('cls', axis=1), train_data['cls'])
    y_pred = clf.predict(test_data.drop('cls', axis=1))
    print("MLPClassifier acc", accuracy_score(test_data['cls'], y_pred))
    print("MLPClassifier rec", recall_score(test_data['cls'], y_pred, average=None))
    print("MLPClassifier pre", precision_score(test_data['cls'], y_pred, average=None))
    print("MLPClassifier f1", f1_score(test_data['cls'], y_pred, average=None))
    print("MLPClassifier roc", roc_auc_score(test_data['cls'], y_pred, average=None))

    # Voting Classifier##################################################
    clf1 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(128, 64), random_state=1)
    clf2 = LogisticRegression()
    clf3 = SGDClassifier(loss="modified_huber")
    eclf = VotingClassifier(estimators=[('neu', clf1), ('log', clf2), ('sgdc', clf3)],
                            voting='soft')

    eclf.fit(train_data.drop('cls', axis=1), train_data['cls'])
    y_pred = eclf.predict(test_data.drop(['cls'], axis=1))
    print("VotingClassifier acc", accuracy_score(test_data['cls'], y_pred))
    print("VotingClassifier rec", recall_score(test_data['cls'], y_pred, average=None))
    print("VotingClassifier pre", precision_score(test_data['cls'], y_pred, average=None))
    print("VotingClassifier f1", f1_score(test_data['cls'], y_pred, average=None))
    print("VotingClassifier roc", roc_auc_score(test_data['cls'], y_pred, average=None))
